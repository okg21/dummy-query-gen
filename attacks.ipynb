{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c193ccd6-ff43-4cd1-8566-9bbbf1330b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import importlib\n",
    "from openai import OpenAI\n",
    "\n",
    "import constants # Required for the following line if kernel is restarted\n",
    "importlib.reload(constants) # Else the old key value is retained\n",
    "from constants import openai_api\n",
    "\n",
    "client = OpenAI(api_key=openai_api)\n",
    "CSV_FILE_NAME = \"sample_output_r10_c3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2284d373-8304-4662-bd5b-35b003584b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query was detected as rank 1\n",
      "Original query was detected as rank 2\n",
      "Original query was detected as rank 1\n",
      "Original query was detected as rank 6\n",
      "Original query was detected as rank 8\n",
      "Original query was detected as rank 1\n",
      "Original query was detected as rank 7\n",
      "Original query was detected as rank 4\n",
      "Original query was detected as rank 1\n",
      "Average success rank: 3.4444444444444446\n",
      "Average success count: 0.9\n"
     ]
    }
   ],
   "source": [
    "def attack_with_gpt():\n",
    "    with open(CSV_FILE_NAME, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    headers = rows[0]\n",
    "    data = rows[1:]\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    shuffled_rows = [headers] + data\n",
    "    \n",
    "    formatted_data = \"\\n\".join([\", \".join(row) for row in shuffled_rows])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a query analysis assistant. Below is a CSV file containing rows of sequential queries.\n",
    "    Each row corresponds to a different topic, and each column represents a sequential query flow.\n",
    "    Only one of the rows is a geniune query flow made by a human user, the rest are AI generated\n",
    "    to twart any adversary from figuring out what the actual search intention is. Your task is to \n",
    "    analyze the queries in each row and identify which one is the real, human-generated query. \n",
    "    Rank your predictions and return the top 10. Return them in a JSON format where the key is \n",
    "    the prediction rank and the value is the row index of the original query.\n",
    "\n",
    "    CSV Data:\n",
    "    {formatted_data}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a query analysis assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        temperature=0.7,\n",
    "        seed=random.randint(0, 1000000)\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    return result\n",
    "\n",
    "def evaluate_multiple_times(csv_path, api_key, iterations):\n",
    "    with open(csv_path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    headers = rows[0]\n",
    "    data = rows[1:]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        random.shuffle(data)\n",
    "        shuffled_csv_path = f\"shuffled_{i}_{csv_path}\"\n",
    "\n",
    "        with open(shuffled_csv_path, mode='w', newline='') as shuffled_file:\n",
    "            writer = csv.writer(shuffled_file)\n",
    "            writer.writerow(headers)\n",
    "            writer.writerows(data)\n",
    "\n",
    "        print(f\"Iteration {i + 1}: Shuffled rows and analyzing...\")\n",
    "        gpt_analysis = analyze_csv_with_gpt(shuffled_csv_path, api_key)\n",
    "        evaluate_results(gpt_analysis)\n",
    "\n",
    "def evaluate_results(gpt_results):\n",
    "    import json\n",
    "    results = json.loads(gpt_results)\n",
    "\n",
    "    for rank, row_index in results.items():\n",
    "        if row_index == 0:\n",
    "            print(f\"Original query was detected as rank {rank}\")\n",
    "            return int(rank)\n",
    "    return -1\n",
    "            \n",
    "\n",
    "N_ATTACKS = 10\n",
    "success_rank_sum = 0\n",
    "success_count_sum = 0\n",
    "for i in range(N_ATTACKS):\n",
    "    gpt_result = attack_with_gpt()\n",
    "    #print(gpt_result)\n",
    "    rank = evaluate_results(gpt_result)\n",
    "    if rank > 0:\n",
    "        success_rank_sum += rank\n",
    "        success_count_sum += 1\n",
    "print(f\"Average success rank: {success_rank_sum / success_count_sum}\")\n",
    "print(f\"Average success count: {success_count_sum / N_ATTACKS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062cdec-6512-4085-b916-66213f42a682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
